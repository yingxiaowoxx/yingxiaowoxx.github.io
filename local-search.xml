<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Probability_Theory</title>
    <link href="/Mathematics/Probability-Theory/"/>
    <url>/Mathematics/Probability-Theory/</url>
    
    <content type="html"><![CDATA[<p><em>This blog just works as a formula stack.</em></p><span id="more"></span><h2 id="Formula"><a href="#Formula" class="headerlink" title="Formula"></a>Formula</h2><h3 id="Law-of-Total-Probability"><a href="#Law-of-Total-Probability" class="headerlink" title="Law of Total Probability"></a>Law of Total Probability</h3><p><strong>IF</strong>: {${A_{i}:i&#x3D;1,2,3…,n}$} is a finite or countably infinite partition of a sample space.</p><p><strong>THEN</strong> for any event $B$:<br>$$ P(B)&#x3D;\sum_{i&#x3D;1}^n P(A_{i})P(B|A_{i}) $$</p><h3 id="Bayes’-Theorem"><a href="#Bayes’-Theorem" class="headerlink" title="Bayes’ Theorem"></a>Bayes’ Theorem</h3><p><strong>IF</strong>:{${A_{i}:i&#x3D;1,2,3,…,n}$} is a finite or countably infinite partition of a sample space (happens firstly), and $B$ is a fixed event(happens secondly).</p><p><strong>THEN</strong> for any event $A_{k}(k\in{1,2,3,…,n})$:<br>$$<br>P(A_{k}|B)&#x3D;\frac{P(A_{k})P(B|A_{k})}{\sum_{i&#x3D;1}^nP(A_{i})P(B|A_{i})}<br>$$</p><h3 id="Binomial-Distribution"><a href="#Binomial-Distribution" class="headerlink" title="Binomial Distribution"></a>Binomial Distribution</h3><p><strong>IF</strong>  the random variable $X$ follows the binomial distribution with and $p ∈ [0,1]$, we write $X \sim B(n, p)$. </p><p><strong>THEN</strong>The probability of getting exactly <em>k successes in n independent Bernoulli trials</em> is given by the probability mass function :<br>$$<br>P\left(X&#x3D;k\right)&#x3D;C_{n}^kp^k(1-p)^k<br>$$</p><h3 id="Poisson-Distribution"><a href="#Poisson-Distribution" class="headerlink" title="Poisson Distribution"></a>Poisson Distribution</h3><p><strong>IF</strong> a discrete random variable X is said to have a Poisson distribution, with parameter $\lambda&gt;0$, we write $X \sim P(\lambda)$ or $X \sim \pi(\lambda)$. </p><p><strong>THEN</strong> it has a probability mass function given by :<br>$$<br>P\left(X&#x3D;k\right)&#x3D;\frac{\lambda_{k}}{k!}e^{-\lambda}<br>$$</p><h3 id="Continuous-Uniform-Distribution"><a href="#Continuous-Uniform-Distribution" class="headerlink" title="Continuous Uniform Distribution"></a>Continuous Uniform Distribution</h3><p><strong>IF</strong>  the <em>probability density function</em> of the continuous uniform distribution $x$ is :<br>$$f(x) &#x3D; \begin{cases}<br>\frac{1}{b-a},&amp; a&lt;x&lt;b\\<br>0,&amp; else \\<br>\end{cases}$$<br><strong>THEN</strong> we write $X \sim U(a,b)$, and the <em>cumulative distribution function</em> is :<br>$$F(x) &#x3D; \begin{cases}<br>0,&amp; x&lt;a\\<br>\frac{x-a}{b-a},&amp; a \leq x &lt; b \\<br>1,&amp; x \geq b<br>\end{cases}$$</p><h3 id="Exponential-distribution"><a href="#Exponential-distribution" class="headerlink" title="Exponential distribution"></a>Exponential distribution</h3><p><strong>IF</strong>  the <em>probability density function</em> of the continuous uniform distribution $x$ and the <em>rate parameter</em> $\lambda &gt; 0$ is :<br>$$f(x;\lambda) &#x3D; \begin{cases}<br>\lambda e^{-\lambda x},&amp; x\geq 0 \\<br>0,&amp; x&lt;0 \\<br>\end{cases}$$<br><strong>THEN</strong> we write $X \sim E(\lambda)$, and the <em>cumulative distribution function</em> is given by :<br>$$F(x)&#x3D;\begin{cases}<br>1-e^{-\lambda x},&amp;x \geq 0\\<br>0,&amp;x&lt;0\\<br>\end{cases}$$</p><h3 id="Normal-Distribution"><a href="#Normal-Distribution" class="headerlink" title="Normal Distribution"></a>Normal Distribution</h3><p><em>Normal distribution</em>, also called <em>Gaussian distribution</em>.</p><p><strong>IF</strong> there is <em>a real-valued random variable  X</em>, and the general form of its <em>probability density function</em> is:<br>$$<br>f(x)&#x3D;\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}<br>$$<br><strong>THEN</strong> We write $X \sim N(\mu,\sigma^2)$. The parameter $\mu$ is the <em>mean or expectation</em> of the distribution (and also its median and mode), while the parameter $\sigma$ is its <em>standard deviation</em>. The <em>variance</em> of the distribution is $\sigma^2$.</p><h3 id="Standard-Normal-Distribution"><a href="#Standard-Normal-Distribution" class="headerlink" title="Standard Normal Distribution"></a>Standard Normal Distribution</h3><p><strong>IF</strong> $X \sim N(\mu,\sigma^2)$. </p><p><strong>THEN</strong> when $\mu&#x3D;0,\sigma&#x3D;1$, we write $X \sim N(0,1)$. It is described by this <em>probability density function</em>:<br>$$<br>\varphi(x) &#x3D; \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}<br>$$</p><p>and the <em>cumulative distribution function</em> is given by :<br>$$<br>\phi(x) &#x3D; \frac{1}{\sqrt{2\pi}}\int_{-\infty}^x e^{-\frac{t^2}{2}} dt<br>$$</p><p><i><font color="gray">To Be Continued…</font></i></p>]]></content>
    
    
    <categories>
      
      <category>Mathematics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Math</tag>
      
      <tag>Probability Theory</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CSAPP_Chapter1</title>
    <link href="/Computer-Science/CSapp-Chapter-1/"/>
    <url>/Computer-Science/CSapp-Chapter-1/</url>
    
    <content type="html"><![CDATA[<center><font size ='5'><i>Computer System A Programmers Perspective</i></font></center><span id="more"></span>This book is written from a programmer's perspective which describes how application programmers can use their knowledge of a system to write better programs. <hr><h2 id="Chapter-1"><a href="#Chapter-1" class="headerlink" title="Chapter 1"></a>Chapter 1</h2><hr><h3 id="1-1-Lifetime-of-hello-c"><a href="#1-1-Lifetime-of-hello-c" class="headerlink" title="1.1 Lifetime of hello.c:"></a>1.1 Lifetime of hello.c:</h3><p>This book begins its study of systems by tracing the lifetime of the hello program, from the time it is created by a programmer, until it runs on a system, prints its simple message, and terminates.</p><p> <em>hello.c</em> :</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;stdio.h&gt;</span></span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&#x27;Hello world!&#x27;</span>);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>Lifetime of hello.c:<br><img src="https://cdn.jsdelivr.net/gh/yingxiaowoxx/Blog-img/img/lifetime_of_hello.png" alt="lifetime_of_hello"></p><hr><h3 id="1-2-Hardware"><a href="#1-2-Hardware" class="headerlink" title="1.2 Hardware"></a>1.2 Hardware</h3><p>Hardware organization of a typical system:<br><img src="https://cdn.jsdelivr.net/gh/yingxiaowoxx/Blog-img/img/Hardware_organization.png" alt="Hardware_organization"></p><ul><li><p><em>Buses</em>: a collection of electrical conduits running through the system.</p></li><li><p><em>Main Memory</em>: <u>a temporary storage device</u> consisting of a collection of <em>dynamic random access memory(DRAM)</em> chips. </p></li><li><p><em>Processor</em>: <em>Centural Processing Unit(CPU)</em>, is the engine that interprets (or executes) instructions stored in main memory. At its core is a word-sized storage device (or register) called the <em>program counter (PC)</em>.</p></li></ul><hr><h3 id="1-3-Runing-the-hello-programme"><a href="#1-3-Runing-the-hello-programme" class="headerlink" title="1.3 Runing the hello programme"></a>1.3 Runing the <em>hello</em> programme</h3><p><img src="https://cdn.jsdelivr.net/gh/yingxiaowoxx/Blog-img/img/Reading.png" alt="Reading"><br><img src="https://cdn.jsdelivr.net/gh/yingxiaowoxx/Blog-img/img/Writing.png" alt="Writing"><br><img src="https://cdn.jsdelivr.net/gh/yingxiaowoxx/Blog-img/img/Loading.png" alt="Loading"></p><ul><li><p><em>Cache</em>: Because the processor can<br>read data from the register file almost <strong>100 times faster</strong> than from memory. To deal with the processor-memory gap, system designers include smaller faster storage devices called <em>cache memories</em>.</p><ul><li><em>L1 Cache</em> : holding tens of thousands of bytes and can be accessed nearly as fast as the <strong>register file</strong>, using <em>static random access memory (SRAM)</em>.</li><li><em>L2 cache</em> : hundreds of thousands to millions of bytes is connected to the <strong>processor</strong> by a special bus, using <em>static random access memory (SRAM)</em>.</li><li><em>L3 cache</em> : It is specialized memory developed to <strong>improve the performance of L1 and L2</strong>. L1 or L2 can be significantly faster than L3, though L3 is usually double the speed of DRAM.</li></ul></li></ul><hr><h3 id="1-4-Storage-Devices-Form-a-Hierarchy"><a href="#1-4-Storage-Devices-Form-a-Hierarchy" class="headerlink" title="1.4 Storage Devices Form a Hierarchy"></a>1.4 Storage Devices Form a Hierarchy</h3><p>The main idea of a memory hierarchy is that storage at one level serves as a<br>cache for storage at the next lower level.<br><img src="https://cdn.jsdelivr.net/gh/yingxiaowoxx/Blog-img/img/An_example_o_a_memory_hierarchy..png" alt="An_example_o_a_memory_hierarchy."></p><hr><h3 id="1-5-The-Operating-System-Manages-the-Hardware"><a href="#1-5-The-Operating-System-Manages-the-Hardware" class="headerlink" title="1.5 The Operating System Manages the Hardware"></a>1.5 The Operating System Manages the Hardware</h3><p><strong>Operating System</strong> works as a bridge between application programs <font color="gray">(hello program)</font>. and hardware <font color="gray">(keyboard, display, disk, or main memory)</font>.<br><img src="https://cdn.jsdelivr.net/gh/yingxiaowoxx/Blog-img/img/Operating_System.png" alt="Operating_System"><br>The operating system has two primary purposes: </p><ol><li>To <strong>protect the hardware</strong> from misuse by runaway applications. </li><li>To provide <strong>applications with simple and uniform mechanisms</strong> for manipulating complicated and often wildly different low-level hardware devices.</li></ol><p>The operating system achieves both goals via the fundamental abstractions shown bellow: <em>processes, virtual memory, and<br>files</em>.<br><img src="https://cdn.jsdelivr.net/gh/yingxiaowoxx/Blog-img/img/Abstractions.png" alt="Abstractions"></p><ul><li><p><em>Process</em>: A <em>process</em> is <strong>the operating system’s abstraction for a running program</strong>. Multiple processes can run concurrently on the same system, and each process appears to have exclusive use of the hardware. At any point in time, a uniprocessor system can only execute the code for a single process.When the operating system decides to transfer control from the current process to some new process, it performs a <em>context switch</em>.<br><img src="https://cdn.jsdelivr.net/gh/yingxiaowoxx/Blog-img/img/Process_context_switch.png" alt="Process_context_switch"></p></li><li><p><em>Threads</em> :Although we normally think of a process as having a single control flow, in modern systems a <strong>process can actually consist of multiple execution units</strong>, called <em>threads</em>, each running in the context of the process and sharing the same code and global data.</p></li><li><p><em>Virtual Memory</em>: It is an abstraction that provides each process with the illusion that it as exclusive use of the main memory. Each process has the same uniform view of memory, which is known as its <em>virtual address space</em>. The basic idea is to <strong>store</strong> the contents of a process’s virtual memory <strong>on disk</strong>, and then <strong>use</strong> the main memory as a cache <strong>for the disk</strong>.</p><ul><li><em>Program code and data</em>: Code begins at the same <strong>fixed address</strong> for all processes, followed by data locations that correspond to globalCvariables.</li><li><em>Heap</em>: It <strong>expands and contracts dynamically</strong> at run time as a result of calls to C standard library routines such as <em>malloc</em> and <em>free</em>.</li><li><em>Shared libraries</em>: Such as the <em>C standard library</em> and the <em>math library</em>.</li><li><em>Stack</em>: Where the compiler uses to implement function calls.Like the heap, it expands and contracts dynamically during the execution of the program.</li><li><em>Kernel virtual memory</em>: The kernel is <strong>the part of the operating system</strong> that is always resident in memory.</li></ul></li></ul><p><img src="https://cdn.jsdelivr.net/gh/yingxiaowoxx/Blog-img/img/Process_virtual_address_space..png" alt="Process_virtual_address_space."></p><ul><li><em>File</em>: It is a sequence of bytes.</li></ul><h3 id="1-5-Concurrency-and-Parallelism"><a href="#1-5-Concurrency-and-Parallelism" class="headerlink" title="1.5 Concurrency and Parallelism"></a>1.5 Concurrency and Parallelism</h3><p><em>Concurrency</em>: It refers to <strong>the general concept</strong> of a system with <em>multiple, simultaneous activities</em>.</p><p><em>Parallelism</em>: It refers to <strong>the use of concurrency</strong> to make a system <strong>run faster</strong>.</p><p><i><font color="gray">To Be Continued…</font></i></p>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Computer Scinece</tag>
      
      <tag>Programming</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello_world</title>
    <link href="/Notes/Hello_world/"/>
    <url>/Notes/Hello_world/</url>
    
    <content type="html"><![CDATA[<h3 id="Hello！"><a href="#Hello！" class="headerlink" title="Hello！"></a>Hello！</h3><p>这是一次建立博客的尝试，本博客采用<a href="https://hexo.io/" title="hexo">hexo</a>博客框架,并且部署于<a href="https://github.com/" title="Github">Github</a>的服务器中，本博客仅作为本人的笔记站及交流学习使用，未经许可，不得转载。</p><span id="more"></span><hr><h3 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h3><p>在日常的使用过程之中，使用<code>$ hexo new post &quot;post_name&quot; </code>新建一页博客，通过编辑之后，使用<code>$ hexo s</code>进行本地查看和管理。</p><p>在本地的调试完成之后，通过<code>$ hexo g</code>生成静态文件至public文件夹，使用<code>$ hexo d</code>将生成的静态文件push到对应的<a href="%22https://github.com/yingxiaowoxx/yingxiaowoxx.github.io%22" title="yingxiaowoxx.github.io">Github</a>仓库中，最后使用<code>$ hexo clean</code>清除本地缓存。</p><p>使用过程之中，<em>Markdown</em>的官方语法通过查询<a href="https://www.markdownguide.org/basic-syntax/" title="Markdown Guide">Markdown官方网站</a>实现。</p>]]></content>
    
    
    <categories>
      
      <category>Notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Notes</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
