<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Probability_Theory</title>
    <link href="/Mathematics/Probability-Theory/"/>
    <url>/Mathematics/Probability-Theory/</url>
    
    <content type="html"><![CDATA[<p><em>This blog just works as a formula stack.</em></p><span id="more"></span><h2 id="Formula"><a href="#Formula" class="headerlink" title="Formula"></a>Formula</h2><h3 id="Law-of-Total-Probability"><a href="#Law-of-Total-Probability" class="headerlink" title="Law of Total Probability:"></a>Law of Total Probability:</h3><p><strong>IF</strong>: {${A_{i}:i&#x3D;1,2,3…,n}$} is a finite or countably infinite partition of a sample space.</p><p><strong>THEN</strong> for any event $B$:<br>$$ P(B)&#x3D;\sum_{i&#x3D;1}^n P(A_{i})P(B|A_{i}) $$</p><h3 id="Bayes’-Theorem"><a href="#Bayes’-Theorem" class="headerlink" title="Bayes’ Theorem"></a>Bayes’ Theorem</h3><p><strong>IF</strong>:{${A_{i}:i&#x3D;1,2,3,…,n}$} is a finite or countably infinite partition of a sample space (happens firstly), and $B$ is a fixed event(happens secondly).</p><p><strong>THEN</strong> for any event $A_{k}(k\in{1,2,3,…,n})$:<br>$$<br>P(A_{k}|B)&#x3D;\frac{P(A_{k})P(B|A_{k})}{\sum_{i&#x3D;1}^nP(A_{i})P(B|A_{i})}<br>$$</p><h3 id="Binomial-Distribution"><a href="#Binomial-Distribution" class="headerlink" title="Binomial Distribution"></a>Binomial Distribution</h3><p><strong>IF</strong>  the random variable $X$ follows the binomial distribution with and $p ∈ [0,1]$, we write $X \sim B(n, p)$. </p><p><strong>THEN</strong>The probability of getting exactly <em>k successes in n independent Bernoulli trials</em> is given by the probability mass function :<br>$$<br>P\left(X&#x3D;k\right)&#x3D;C_{n}^kp^k(1-p)^k<br>$$</p><h3 id="Poisson-Distribution"><a href="#Poisson-Distribution" class="headerlink" title="Poisson Distribution"></a>Poisson Distribution</h3><p><strong>IF</strong> a discrete random variable X is said to have a Poisson distribution, with parameter $\lambda&gt;0$, we write $X \sim P(\lambda)$ or $X \sim \pi(\lambda)$. </p><p><strong>THEN</strong> it has a probability mass function given by :<br>$$<br>P\left(X&#x3D;k\right)&#x3D;\frac{\lambda_{k}}{k!}e^{-\lambda}<br>$$</p><h3 id="Continuous-Uniform-Distribution"><a href="#Continuous-Uniform-Distribution" class="headerlink" title="Continuous Uniform Distribution"></a>Continuous Uniform Distribution</h3><p><strong>IF</strong>  the <em>probability density function</em> of the continuous uniform distribution $x$ is :<br>$$f(x) &#x3D; \begin{cases}<br>\frac{1}{b-a},&amp; a&lt;x&lt;b\\<br>0,&amp; else \\<br>\end{cases}$$<br><strong>THEN</strong> we write $X \sim U(a,b)$, and the <em>cumulative distribution function</em> is :<br>$$F(x) &#x3D; \begin{cases}<br>0,&amp; x&lt;a\\<br>\frac{x-a}{b-a},&amp; a \leq x &lt; b \\<br>1,&amp; x \geq b<br>\end{cases}$$</p><h3 id="Exponential-distribution"><a href="#Exponential-distribution" class="headerlink" title="Exponential distribution"></a>Exponential distribution</h3><p><strong>IF</strong>  the <em>probability density function</em> of the continuous uniform distribution $x$ and the <em>rate parameter</em> $\lambda &gt; 0$ is :<br>$$f(x;\lambda) &#x3D; \begin{cases}<br>\lambda e^{-\lambda x},&amp; x\geq 0 \\<br>0,&amp; x&lt;0 \\<br>\end{cases}$$<br><strong>THEN</strong> we write $X \sim E(\lambda)$, and the <em>cumulative distribution function</em> is given by :<br>$$F(x)&#x3D;\begin{cases}<br>1-e^{-\lambda x},&amp;x \geq 0\\<br>0,&amp;x&lt;0\\<br>\end{cases}$$</p><h3 id="Normal-Distribution"><a href="#Normal-Distribution" class="headerlink" title="Normal Distribution"></a>Normal Distribution</h3><p><em>Normal distribution</em>, also called <em>Gaussian distribution</em>.</p><p><strong>IF</strong> there is <em>a real-valued random variable  X</em>, and the general form of its <em>probability density function</em> is:<br>$$<br>f(x)&#x3D;\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}<br>$$<br><strong>THEN</strong> We write $X \sim N(\mu,\sigma^2)$. The parameter $\mu$ is the <em>mean or expectation</em> of the distribution (and also its median and mode), while the parameter $\sigma$ is its <em>standard deviation</em>. The <em>variance</em> of the distribution is $\sigma^2$.</p><h3 id="Standard-Normal-Distribution"><a href="#Standard-Normal-Distribution" class="headerlink" title="Standard Normal Distribution"></a>Standard Normal Distribution</h3><p><strong>IF</strong> $X \sim N(\mu,\sigma^2)$. </p><p><strong>THEN</strong> when $\mu&#x3D;0,\sigma&#x3D;1$, we write $X \sim N(0,1)$. It is described by this <em>probability density function</em>:<br>$$<br>\varphi(x) &#x3D; \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}<br>$$</p><p>and the <em>cumulative distribution function</em> is given by :<br>$$<br>\phi(x) &#x3D; \frac{1}{\sqrt{2\pi}}\int_{-\infin}^x e^{-\frac{t^2}{2}} dt<br>$$</p><p><i><font color="gray">To Be Continued…</font></i></p>]]></content>
    
    
    <categories>
      
      <category>Mathematics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Math</tag>
      
      <tag>Probability Theory</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CSAPP_Chapter1</title>
    <link href="/Computer-Science/CSapp-Chapter-1/"/>
    <url>/Computer-Science/CSapp-Chapter-1/</url>
    
    <content type="html"><![CDATA[<center><font size ='5'><i>Computer System A Programmers Perspective</i></font></center><span id="more"></span>This book is written from a programmer's perspective which describes how application programmers can use their knowledge of a system to write better programs. <h2 id="Chapter-1"><a href="#Chapter-1" class="headerlink" title="Chapter 1"></a>Chapter 1</h2><h3 id="Lifetime-of-hello-c"><a href="#Lifetime-of-hello-c" class="headerlink" title="Lifetime of hello.c:"></a>Lifetime of hello.c:</h3><p>This book begins its study of systems by tracing the lifetime of the hello program, from the time it is created by a programmer, until it runs on a system, prints its simple message, and terminates.</p><p> <em>hello.c</em> :</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;stdio.h&gt;</span></span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&#x27;Hello world!&#x27;</span>);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>Lifetime of hello.c:<br><img src="https://cdn.jsdelivr.net/gh/yingxiaowoxx/Blog-img/img/lifetime_of_hello.png" alt="lifetime_of_hello"></p><h3 id="Hardware"><a href="#Hardware" class="headerlink" title="Hardware"></a>Hardware</h3><p>Hardware organization of a typical system:<br><img src="https://cdn.jsdelivr.net/gh/yingxiaowoxx/Blog-img/img/Hardware_organization.png" alt="Hardware_organization"></p><ul><li><p><em>Buses</em>: a collection of electrical conduits running through the system.</p></li><li><p><em>Main Memory</em>: <u>a temporary storage device</u> consisting of a collection of <em>dynamic random access memory(DRAM)</em> chips. </p></li><li><p><em>Processor</em>: <em>Centural Processing Unit(CPU)</em>, is the engine that interprets (or executes) instructions stored in main memory. At its core is a word-sized storage device (or register) called the <em>program counter (PC)</em>.</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/yingxiaowoxx/Blog-img/img/Reading.png" alt="Reading"><br><img src="https://cdn.jsdelivr.net/gh/yingxiaowoxx/Blog-img/img/Writing.png" alt="Writing"><br><img src="https://cdn.jsdelivr.net/gh/yingxiaowoxx/Blog-img/img/Loading.png" alt="Loading"></p><ul><li><em>Cache</em>:</li></ul><p><i><font color="gray">To Be Continued…</font></i></p>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Computer Scinece</tag>
      
      <tag>Programming</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello_world</title>
    <link href="/Notes/Hello_world/"/>
    <url>/Notes/Hello_world/</url>
    
    <content type="html"><![CDATA[<h3 id="Hello！"><a href="#Hello！" class="headerlink" title="Hello！"></a>Hello！</h3><p>这是一次建立博客的尝试，本博客采用<a href="https://hexo.io/" title="hexo">hexo</a>博客框架,并且部署于<a href="https://github.com/" title="Github">Github</a>的服务器中，本博客仅作为本人的笔记站及交流学习使用，未经许可，不得转载。</p><span id="more"></span><hr><h3 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h3><p>在日常的使用过程之中，使用<code>$ hexo new post &quot;post_name&quot; </code>新建一页博客，通过编辑之后，使用<code>$ hexo s</code>进行本地查看和管理。</p><p>在本地的调试完成之后，通过<code>$ hexo g</code>生成静态文件至public文件夹，使用<code>$ hexo d</code>将生成的静态文件push到对应的<a href="%22https://github.com/yingxiaowoxx/yingxiaowoxx.github.io%22" title="yingxiaowoxx.github.io">Github</a>仓库中，最后使用<code>$ hexo clean</code>清除本地缓存。</p><p>使用过程之中，<em>Markdown</em>的官方语法通过查询<a href="https://www.markdownguide.org/basic-syntax/" title="Markdown Guide">Markdown官方网站</a>实现。</p>]]></content>
    
    
    <categories>
      
      <category>Notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Notes</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
